{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec643e2f",
   "metadata": {},
   "source": [
    "# Logistic Regression Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d2a92",
   "metadata": {},
   "source": [
    "\n",
    "我们使用作业里的野火数据，通过图表和数据展示 Logistic Regression 的原理：\n",
    "\n",
    "1. 读取与预处理数据（目标二值化 + 特征标准化）。\n",
    "2. 查看类别分布与 Sigmoid 曲线。\n",
    "3. 训练 scikit-learn 的 LogisticRegression 并输出指标与混淆矩阵。\n",
    "4. 手写梯度下降版本，观察损失和准确率随迭代的变化。\n",
    "5. 仅用温度与湿度两个特征画出决策边界。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbdd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "DATA_DIR = Path.cwd()\n",
    "TRAIN_PATH = DATA_DIR / 'wildfires_training.csv'\n",
    "TEST_PATH = DATA_DIR / 'wildfires_test.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ddd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1f99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = train_df['fire'].map({'yes': 1, 'no': 0}).astype(int)\n",
    "X_train = train_df.drop(columns='fire')\n",
    "y_test = test_df['fire'].map({'yes': 1, 'no': 0}).astype(int)\n",
    "X_test = test_df.drop(columns='fire')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "print('Scaled train shape:', X_train_std.shape)\n",
    "print('Scaled test shape :', X_test_std.shape)\n",
    "print('\n",
    "Training class counts:')\n",
    "print(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = y_train.value_counts().sort_index().plot(kind='bar', color=['tab:blue', 'tab:red'])\n",
    "ax.set_xlabel('Label (0=no fire, 1=fire)')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Training class distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac42192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = np.linspace(-8, 8, 400)\n",
    "plt.plot(z, 1 / (1 + np.exp(-z)))\n",
    "plt.axvline(0, color='0.5', linestyle='--', alpha=0.6)\n",
    "plt.axhline(0.5, color='0.5', linestyle='--', alpha=0.6)\n",
    "plt.xlabel('Linear combination z')\n",
    "plt.ylabel('Sigmoid(z)')\n",
    "plt.title('Sigmoid function')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde2126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train_std, y_train)\n",
    "\n",
    "train_pred = model.predict(X_train_std)\n",
    "test_pred = model.predict(X_test_std)\n",
    "print(f\"Train accuracy: {accuracy_score(y_train, train_pred):.4f}\")\n",
    "print(f\"Test accuracy : {accuracy_score(y_test, test_pred):.4f}\n",
    "\")\n",
    "print('Classification report (test set):')\n",
    "print(classification_report(y_test, test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion matrix (baseline model)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4160b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_np = X_train_std.astype(float)\n",
    "X_test_np = X_test_std.astype(float)\n",
    "y_train_np = y_train.to_numpy(dtype=float)\n",
    "y_test_np = y_test.to_numpy(dtype=float)\n",
    "\n",
    "weights = np.zeros(X_train_np.shape[1])\n",
    "bias = 0.0\n",
    "learning_rate = 0.1\n",
    "epochs = 400\n",
    "\n",
    "history = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    scores = X_train_np @ weights + bias\n",
    "    probs = 1 / (1 + np.exp(-scores))\n",
    "\n",
    "    loss = -np.mean(y_train_np * np.log(probs + 1e-15) + (1 - y_train_np) * np.log(1 - probs + 1e-15))\n",
    "    train_acc = (probs >= 0.5).astype(int).mean() if y_train_np.ndim == 0 else ((probs >= 0.5).astype(int) == y_train_np).mean()\n",
    "    test_probs = 1 / (1 + np.exp(-(X_test_np @ weights + bias)))\n",
    "    test_acc = ((test_probs >= 0.5).astype(int) == y_test_np).mean()\n",
    "    history.append((epoch, loss, train_acc, test_acc))\n",
    "\n",
    "    error = probs - y_train_np\n",
    "    grad_w = X_train_np.T @ error / len(y_train_np)\n",
    "    grad_b = error.mean()\n",
    "    weights -= learning_rate * grad_w\n",
    "    bias -= learning_rate * grad_b\n",
    "\n",
    "    if epoch % 50 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch:3d} | loss={loss:.4f} | train_acc={train_acc:.3f} | test_acc={test_acc:.3f}\")\n",
    "\n",
    "final_train_acc = ((1 / (1 + np.exp(-(X_train_np @ weights + bias))) >= 0.5).astype(int) == y_train_np).mean()\n",
    "final_test_acc = ((1 / (1 + np.exp(-(X_test_np @ weights + bias))) >= 0.5).astype(int) == y_test_np).mean()\n",
    "print(f\"\n",
    "Manual GD model -> train_acc={final_train_acc:.4f}, test_acc={final_test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fe25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history_df = pd.DataFrame(history, columns=['epoch', 'loss', 'train_acc', 'test_acc'])\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].plot(history_df['epoch'], history_df['loss'])\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Binary cross-entropy loss')\n",
    "axes[0].set_title('Loss over epochs')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(history_df['epoch'], history_df['train_acc'], label='train')\n",
    "axes[1].plot(history_df['epoch'], history_df['test_acc'], label='test')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_ylim(0.6, 1.0)\n",
    "axes[1].set_title('Accuracy over epochs')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a84585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['temp', 'humidity']\n",
    "X_train_2d = X_train[cols]\n",
    "X_test_2d = X_test[cols]\n",
    "\n",
    "scaler_2d = StandardScaler()\n",
    "X_train_2d_std = scaler_2d.fit_transform(X_train_2d)\n",
    "X_test_2d_std = scaler_2d.transform(X_test_2d)\n",
    "\n",
    "model_2d = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model_2d.fit(X_train_2d_std, y_train)\n",
    "print(f\"2D model test accuracy: {accuracy_score(y_test, model_2d.predict(X_test_2d_std)):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X_train_2d_std[:, 0].min() - 1, X_train_2d_std[:, 0].max() + 1, 200),\n",
    "    np.linspace(X_train_2d_std[:, 1].min() - 1, X_train_2d_std[:, 1].max() + 1, 200)\n",
    ")\n",
    "\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "z = model_2d.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.contourf(xx, yy, z, levels=np.linspace(0, 1, 11), cmap='coolwarm', alpha=0.7)\n",
    "plt.contour(xx, yy, z, levels=[0.5], colors='k', linewidths=2)\n",
    "plt.scatter(X_train_2d_std[y_train == 1, 0], X_train_2d_std[y_train == 1, 1], c='tab:red', edgecolor='k', label='fire (train)', alpha=0.7)\n",
    "plt.scatter(X_train_2d_std[y_train == 0, 0], X_train_2d_std[y_train == 0, 1], c='tab:blue', edgecolor='k', label='no fire (train)', alpha=0.7)\n",
    "plt.xlabel('temp (scaled)')\n",
    "plt.ylabel('humidity (scaled)')\n",
    "plt.title('Decision boundary (temp vs humidity)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1e1a93",
   "metadata": {},
   "source": [
    "\n",
    "**总结**：Sigmoid 把线性组合映射成概率，标准化让优化更稳定；梯度下降逐步降低损失；决策边界在标准化后的空间里是一条直线。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
